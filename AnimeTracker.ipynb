from google.colab import drive
drive.mount('/content/drive')  # Cela te permet d'accéder à ton Google Drive

!pip install requests beautifulsoup4 gspread oauth2client

import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import re

# 1. Configuration des accès à Google Sheets
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("/content/drive/MyDrive/Perso/TBATE/Web Anime/credentials.json", scope)
client = gspread.authorize(creds)

# Ouvre ton Google Sheets
spreadsheet = client.open("Scan")  # Utilise le nom du fichier "Scan" ici

# Ouvre l'onglet "Anime"
worksheet = spreadsheet.worksheet("Anime")


# 2. Fonction pour récupérer les données sur VoirAnime
def get_anime_data(url, slug, worksheet):
    records = worksheet.get_all_records()
    episode_vus = 0
    for i, row in enumerate(records):
        if row['Slug'] == slug:
            episode_vus = row['Vus']
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    # Exemple de scraping pour récupérer titre, image et épisodes dispo
    title = soup.find("div", class_="post-title").find("h1").text.strip()
    image_url = soup.find("div",class_="summary_image").find("img")["src"]
    episode_count = re.search(r'\b(\d{2})\b', soup.find("li", class_="wp-manga-chapter").find("a").text.strip()).group(1)  # Nombre d'épisodes dispo
    return title, image_url, episode_count, episode_vus


def get_anime_data_mal(mal_url, id_mal):
    response = requests.get(mal_url)
    soup = BeautifulSoup(response.text, "html.parser")
    name = soup.find("h1", class_="title-name h1_bold_none").text.strip()
    image_url = soup.find("div", class_="leftside").find("img", class_="ac")["data-src"]
    for div in soup.find_all("div", class_="spaceit_pad"):
        label = div.find("span", class_="dark_text")
        if label and label.text.strip() == "Episodes:":
            nb_episode = div.text.replace("Episodes:", "").strip()

    return name, image_url, nb_episode


# 3. Fonction pour mettre à jour Google Sheets
def update_google_sheet(title,slug, image_url, episode_count, episode_vus, worksheet):
    # Ajoute une nouvelle ligne à ton tableau Google Sheets
    # worksheet.append_row([title, slug, episode_vus, episode_count,  image_url])  # Le 0 dans "episodes_vus" indique que tu n'as rien vu encore

    found = False
    records = worksheet.get_all_records()
    for i, row in enumerate(records):
        if row['Slug'] == slug:
          row_index = i + 2
          worksheet.update(f"A{row_index}:D{row_index}", [[title, slug, episode_vus, episode_count]])
          found = True
          break
    if not found:
      worksheet.append_row([title, slug, episode_vus, episode_count,  image_url])  # Le 0 dans "episodes_vus" indique que tu n'as rien vu encore

# 4. Exemple d'URL à scraper
# anime_url_site = "https://v6.voiranime.com/anime/kowloon-generic-romance/"
# slug = "kowloon-generic-romance"
# title, image_url, episode_count, episode_vus = get_anime_data(anime_url, slug, worksheet)


# a faire a chaque saison
# myanimelist = "https://myanimelist.net/anime/"
# id_mal = ["37450"]

# for id in id_mal:
#   mal_url = myanimelist + id + "/"
#   name, image_url, nb_episode = get_anime_data_mal(mal_url, id_mal)
#   print(name)
#   print(image_url)
#   print(nb_episode)



# 5. Met à jour ton Google Sheets

anime_url_site = "https://v6.voiranime.com/anime/"
slug_list = ["kowloon-generic-romance",
             "your-forma",
             "vigilante-boku-no-hero-academia-illegals",
             "wind-breaker-2",
             "the-apothecary-diaries-2",
             "lazarus-jap",
             "the-beginning-after-the-end",
             "from-old-country-bumpkin-to-master-swordsman",
             "to-be-hero-x",
             "the-dinner-table-detective",
             "teogonia",
             "seishun-buta-yarou-wa-bunny-girl-senpai-no-yume-wo-minai"]

for slug in slug_list:
  anime_url = anime_url_site + slug + "/"
  title, image_url, episode_count, episode_vus = get_anime_data(anime_url, slug, worksheet)
  update_google_sheet(title , slug, image_url, episode_count, episode_vus, worksheet)


print("Anime ajouté avec succès à Google Sheets !")
